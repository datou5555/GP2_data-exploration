# GP2_data-exploration
Group Project Part 2: Data exploration, visualization, and preprocessing

## 1. Environment Setup and Data Download
(https://github.com/datou5555/GP2_data-exploration/blob/Milestone2/milestone2_data_exploration(4).ipynb#Step-1--Environment-Setup-and-Data-Download)

    - In this step, we install missing dependencies and download the dataset if it's not already available.
    
    - Install necessary packages (pyspark, nltk, etc.)
    
    - Download or load the dataset from the source (local file or web)

## 2. Spark Session Setup and Data Loading
(https://github.com/datou5555/GP2_data-exploration/blob/Milestone2/milestone2_data_exploration(4).ipynb#Step-2--Spark-Session-Setup-and-Data-Loading
)

    - We load the dataset and check its structure and quality.
    
    - Read file using spark.read.json()
    
    - Display schema, row count, and a sample of the data
    
    - Detect and note missing values or unusual formats

## 3. Data Cleaning and Preprocessing 
(https://github.com/datou5555/GP2_data-exploration/blob/Milestone2/milestone2_data_exploration(4).ipynb#Step-3-Data-Cleaning-and-Preprocessing
)

    - Clean and prepare the text data for analysis.

    - Drop or impute null values
    
    - Normalize text: lowercasing, removing punctuation, etc.
    
    - Tokenization and stopword removal using PySpark NLP functions

## 4. Data Visualization and Correlation  
(https://github.com/datou5555/GP2_data-exploration/blob/Milestone2/milestone2_data_exploration(4).ipynb#Step-6-Data-Visualization-and-Correlation-Analysis)

    - Generate plots to explore patterns in the text or metadata.



